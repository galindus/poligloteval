{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb9153a-12c7-431b-9525-e9fd510d20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XDG_CACHE=/workspace/.cache\n",
      "env: HF_HOME=/workspace/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "%env XDG_CACHE=/workspace/.cache\n",
    "%env HF_HOME=/workspace/.cache/huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43381932-7061-42a9-ade7-27eac3938b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175a0fa0-01d3-4fca-8bcc-fab926fbcb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd63086bd3e4169af2f06fc1dcea7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"projecte-aina/aguila-7b\"\n",
    "#model_id = \"tiiuae/falcon-7b\"\n",
    "model_name = model_id.split('/')[1]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             trust_remote_code=True,\n",
    "                                             device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd8e8d1f-b662-4580-80ff-ff70e95e0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(tensor):\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    scaled_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "    return scaled_tensor\n",
    "\n",
    "\n",
    "def compute_probability(input_text, answer):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    answer_tokens = tokenizer(answer)['input_ids']\n",
    "    answer_probability = 0\n",
    "    with torch.no_grad():\n",
    "        for token in answer_tokens:\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "            # Logits are in the outputs, you can access the last token's logits like this:\n",
    "            logits = outputs.logits[:, -1, :]\n",
    "            #log_probs = torch.log_softmax(logits, dim=-1).cpu()\n",
    "            log_probs = torch.log(min_max_scaling(logits))\n",
    "            answer_probability += log_probs[0][token]\n",
    "\n",
    "            # Prepare input_ids for the next token prediction\n",
    "            new_token = torch.tensor([[token]]).to(model.device)\n",
    "            inputs = {'input_ids': torch.cat([inputs['input_ids'], new_token], dim=1),\n",
    "                    'attention_mask': torch.cat([inputs['attention_mask'], torch.tensor([[1]]).to(model.device)], dim=1)}\n",
    "    return torch.exp(answer_probability).item()\n",
    "    # return answer_probability.item()\n",
    "\n",
    "\n",
    "def run_inference(txt, num_tokens=20, stop_text='\\n'):\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer(txt, return_tensors=\"pt\").to(model.device)['input_ids']\n",
    "    # Calculate the total length of the output (input length + number of tokens to generate)\n",
    "\n",
    "    generated_text = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate tokens\n",
    "        for _ in range(num_tokens):\n",
    "            max_length = len(tokens[0]) + 1\n",
    "            tokens = model.generate(tokens, do_sample=True, top_k=1, eos_token_id=tokenizer.eos_token_id, max_length=max_length)\n",
    "\n",
    "            # Decode the generated tokens into text\n",
    "            generated_text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "\n",
    "            # If a stop text is found, truncate the output at its first occurrence\n",
    "            if stop_text is not None:\n",
    "                if generated_text[-len(stop_text):] == stop_text:\n",
    "                    break\n",
    "\n",
    "        generated_only = generated_text.replace(txt, \"\").strip()\n",
    "        return generated_only\n",
    "\n",
    "\n",
    "def translate(sample):\n",
    "    def translate_to_english(txt):\n",
    "        lines = txt.split(\"\\n\")\n",
    "        toks, _ = tokenizer_ca_en.tokenize_batch(lines)\n",
    "        translated = ca_en_model.translate_batch(toks)\n",
    "        ts = []\n",
    "        for t in translated:\n",
    "            ts.append(tokenizer_ca_en.detokenize(t.hypotheses[0]))\n",
    "\n",
    "        return \"\\n\".join(ts)\n",
    "    en_prompt = translate_to_english(sample['prompt'])\n",
    "    en_answer = translate_to_english(sample['answer'])\n",
    "    return {\"prompt\": en_prompt, \"answer\": en_answer}\n",
    "\n",
    "\n",
    "def compute_metrics(sample):\n",
    "    prob = compute_probability(sample['prompt'], sample['answer'])\n",
    "    prediction = run_inference(sample['prompt'])\n",
    "    f1 = f1_score(prediction, sample['answer'])\n",
    "    bleu = calculate_bleu_score(prediction, sample['answer'])\n",
    "    return {\"prediction\": prediction, \"prob\": prob, \"f1\": f1, \"bleu\": bleu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79d3a1bd-55a2-464a-acec-77d1aeb7a56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e1f6582acc418788ea401344c0997e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c87121e4eac4048b0457f40528f0e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7093b33c9e434d44a5eae52f9e583fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7a790157614a78883e32d257d5b4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a7fde03dbf4911b3fb25a355130233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebcb1dbd7c3405b85cfe4d8201b0b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xquad_ca = load_dataset(\"data\", data_files=\"xquad_ca.csv\", split=\"train\")\n",
    "xquad_en = load_dataset(\"data\", data_files=\"xquad_en.csv\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22f9f86e-25f9-4544-9a35-209cff2edf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c728cb6c8815413bac11040af9b341bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "      <th>f1</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>militant extremista gihadista wahhabita/salafista</td>\n",
       "      <td>gihadista</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9.070367e-233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>àrabs sunnites</td>\n",
       "      <td>Abu Bakr al-Baghdadi</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>deu milions</td>\n",
       "      <td>10 milions de persones</td>\n",
       "      <td>0.644531</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.288230e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>reconeixement</td>\n",
       "      <td>Res</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>\"L'Estat Islàmic\", anteriorment conegut com a ...</td>\n",
       "      <td>califat</td>\n",
       "      <td>el califat</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.531972e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>1756 fins a la signatura del tractat de pau el...</td>\n",
       "      <td>des de 1754 fins a 1760</td>\n",
       "      <td>0.636719</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>3.645526e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>sis anys</td>\n",
       "      <td>des de 1756 fins a 1763</td>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>el 1760</td>\n",
       "      <td>1760</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.702145e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>A Europa, el teatre nord-americà de la guerra ...</td>\n",
       "      <td>batalla de Jumonville Glen</td>\n",
       "      <td>La batalla de Jumonville Glen</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>6.687403e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A causa de tenir cossos tous i gelatinosos, el...</td>\n",
       "      <td>A causa de tenir cossos tous i gelatinosos, el...</td>\n",
       "      <td>tenir cossos tous i gelatinosos</td>\n",
       "      <td>perquè els ctenòfors són extremament fràgils i...</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.024491e-231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "1  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "2  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "3  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "4  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "5  A Europa, el teatre nord-americà de la guerra ...   \n",
       "6  A Europa, el teatre nord-americà de la guerra ...   \n",
       "7  A Europa, el teatre nord-americà de la guerra ...   \n",
       "8  A Europa, el teatre nord-americà de la guerra ...   \n",
       "9  A causa de tenir cossos tous i gelatinosos, el...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "1  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "2  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "3  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "4  \"L'Estat Islàmic\", anteriorment conegut com a ...   \n",
       "5  A Europa, el teatre nord-americà de la guerra ...   \n",
       "6  A Europa, el teatre nord-americà de la guerra ...   \n",
       "7  A Europa, el teatre nord-americà de la guerra ...   \n",
       "8  A Europa, el teatre nord-americà de la guerra ...   \n",
       "9  A causa de tenir cossos tous i gelatinosos, el...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  militant extremista gihadista wahhabita/salafista   \n",
       "1                                     àrabs sunnites   \n",
       "2                                        deu milions   \n",
       "3                                      reconeixement   \n",
       "4                                            califat   \n",
       "5  1756 fins a la signatura del tractat de pau el...   \n",
       "6                                           sis anys   \n",
       "7                                            el 1760   \n",
       "8                         batalla de Jumonville Glen   \n",
       "9                    tenir cossos tous i gelatinosos   \n",
       "\n",
       "                                          prediction      prob        f1  \\\n",
       "0                                          gihadista  0.578125  0.400000   \n",
       "1                               Abu Bakr al-Baghdadi  0.558594  0.000000   \n",
       "2                             10 milions de persones  0.644531  0.333333   \n",
       "3                                                Res  0.550781  0.000000   \n",
       "4                                         el califat  0.765625  0.666667   \n",
       "5                            des de 1754 fins a 1760  0.636719  0.266667   \n",
       "6                            des de 1756 fins a 1763  0.652344  0.000000   \n",
       "7                                               1760  0.757812  0.666667   \n",
       "8                      La batalla de Jumonville Glen  0.730469  0.888889   \n",
       "9  perquè els ctenòfors són extremament fràgils i...  0.511719  0.133333   \n",
       "\n",
       "            bleu  \n",
       "0  9.070367e-233  \n",
       "1   0.000000e+00  \n",
       "2  1.288230e-231  \n",
       "3   0.000000e+00  \n",
       "4  1.531972e-231  \n",
       "5  3.645526e-155  \n",
       "6   0.000000e+00  \n",
       "7  6.702145e-232  \n",
       "8   6.687403e-01  \n",
       "9  1.024491e-231  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ca = xquad_ca.map(compute_metrics)\n",
    "results_ca.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ca.to_csv(f\"results/{model_name}-xquad-ca.csv\", index=False)\n",
    "results_en.to_csv(f\"results/{model_name}-xquad-en.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== CA =====\n",
      "prob    0.638672\n",
      "f1      0.335556\n",
      "bleu    0.066874\n",
      "dtype: float64\n",
      "==== EN =====\n",
      "prob    0.705859\n",
      "f1      0.516364\n",
      "bleu    0.100000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_ca_mean = results_ca.to_pandas()[['prob', 'f1', 'bleu']].mean()\n",
    "results_en_mean = results_en.to_pandas()[['prob', 'f1', 'bleu']].mean()\n",
    "print(\"==== CA =====\")\n",
    "print(results_ca_mean)\n",
    "print(\"==== EN =====\")\n",
    "print(results_en_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
