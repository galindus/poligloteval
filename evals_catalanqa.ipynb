{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb9153a-12c7-431b-9525-e9fd510d20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XDG_CACHE=/workspace/.cache\n",
      "env: HF_HOME=/workspace/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "%env XDG_CACHE=/workspace/.cache\n",
    "%env HF_HOME=/workspace/.cache/huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43381932-7061-42a9-ade7-27eac3938b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pyonmttok\n",
    "import ctranslate2\n",
    "from metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175a0fa0-01d3-4fca-8bcc-fab926fbcb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e57555418c42ecb9a22e4629dfe275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"projecte-aina/aguila-7b\"\n",
    "#model_id = \"tiiuae/falcon-7b\"\n",
    "model_name = model_id.split('/')[1]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             trust_remote_code=True,\n",
    "                                             device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac21dd30-0551-43f9-8d8a-5b04df3a59eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading translator Models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef0def8abb147f9acbe88d00730a09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Lets Do the translation layer\n",
    "from huggingface_hub import snapshot_download\n",
    "print(\"Loading translator Models...\")\n",
    "\n",
    "ca_en_model_folder = snapshot_download(repo_id=\"projecte-aina/mt-aina-ca-en\", revision=\"main\")\n",
    "tokenizer_ca_en = pyonmttok.Tokenizer(\n",
    "    mode=\"none\", sp_model_path=ca_en_model_folder + \"/spm.model\"\n",
    ")\n",
    "ca_en_model = ctranslate2.Translator(ca_en_model_folder, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8e8d1f-b662-4580-80ff-ff70e95e0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(tensor):\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    scaled_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "    return scaled_tensor\n",
    "\n",
    "\n",
    "def compute_probability(input_text, answer):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    answer_tokens = tokenizer(answer)['input_ids']\n",
    "    answer_probability = 0\n",
    "    with torch.no_grad():\n",
    "        for token in answer_tokens:\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "            # Logits are in the outputs, you can access the last token's logits like this:\n",
    "            logits = outputs.logits[:, -1, :]\n",
    "            log_probs = torch.log_softmax(logits, dim=-1).cpu()\n",
    "            # log_probs = torch.log(min_max_scaling(logits))\n",
    "            answer_probability += log_probs[0][token]\n",
    "\n",
    "            # Prepare input_ids for the next token prediction\n",
    "            new_token = torch.tensor([[token]]).to(model.device)\n",
    "            inputs = {'input_ids': torch.cat([inputs['input_ids'], new_token], dim=1),\n",
    "                    'attention_mask': torch.cat([inputs['attention_mask'], torch.tensor([[1]]).to(model.device)], dim=1)}\n",
    "    return torch.exp(answer_probability).item()\n",
    "    # return answer_probability.item()\n",
    "\n",
    "\n",
    "def run_inference(txt, num_tokens=20, stop_text='\\n'):\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer(txt, return_tensors=\"pt\").to(model.device)['input_ids']\n",
    "    # Calculate the total length of the output (input length + number of tokens to generate)\n",
    "\n",
    "    generated_text = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate tokens\n",
    "        for _ in range(num_tokens):\n",
    "            max_length = len(tokens[0]) + 1\n",
    "            tokens = model.generate(tokens, do_sample=True, top_k=1, eos_token_id=tokenizer.eos_token_id, max_length=max_length)\n",
    "\n",
    "            # Decode the generated tokens into text\n",
    "            generated_text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "\n",
    "            # If a stop text is found, truncate the output at its first occurrence\n",
    "            if stop_text is not None:\n",
    "                if generated_text[-len(stop_text):] == stop_text:\n",
    "                    break\n",
    "\n",
    "        generated_only = generated_text.replace(txt, \"\").strip()\n",
    "        return generated_only\n",
    "\n",
    "\n",
    "def translate(sample):\n",
    "    def translate_to_english(txt):\n",
    "        lines = [l for l in txt.split(\"\\n\") if l.strip() != \"\"]\n",
    "\n",
    "        toks, _ = tokenizer_ca_en.tokenize_batch(lines)\n",
    "        translated = ca_en_model.translate_batch(toks)\n",
    "        ts = []\n",
    "        for t in translated:\n",
    "            t_str = tokenizer_ca_en.detokenize(t.hypotheses[0])\n",
    "            # That is a bug on the translation outputing twice the translation.\n",
    "            if len(txt.split(\" \")) == 1 and len(t_str.split(\" \")) == 2:\n",
    "                t_str = t_str.split(\" \")[0]\n",
    "            ts.append(t_str)\n",
    "\n",
    "        return \"\\n\".join(ts)\n",
    "    en_prompt = translate_to_english(sample['prompt'])\n",
    "    en_answer = translate_to_english(sample['answer'])\n",
    "    return {\"prompt\": en_prompt, \"answer\": en_answer}\n",
    "\n",
    "\n",
    "def compute_metrics(sample):\n",
    "    prob = compute_probability(sample['prompt'], sample['answer'])\n",
    "    prediction = run_inference(sample['prompt'])\n",
    "    f1 = f1_score(prediction, sample['answer'])\n",
    "    bleu = calculate_bleu_score(prediction, sample['answer'])\n",
    "    return {\"prediction\": prediction, \"prob\": prob, \"f1\": f1, \"bleu\": bleu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d3a1bd-55a2-464a-acec-77d1aeb7a56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83918d1ef459495c9bcf28dc78759d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbeaeaa86674108a97269242727230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3e20e7471e49a9873a7c99a02ce462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function translate at 0x7fee7f886a70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b53e8cc78c4cea9e169aad833ec4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catalanqa = load_dataset(\"data\", data_files=\"catalanqa.csv\", split=\"train[:10]\")\n",
    "catalanqa_en = catalanqa.map(translate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f9f86e-25f9-4544-9a35-209cff2edf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249b3e495e83467a832116bda2e98425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "      <th>f1</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barcelona en Comú renunciarà a un regidor en t...</td>\n",
       "      <td>en totes les votacions del ple de l'Ajuntament...</td>\n",
       "      <td>un</td>\n",
       "      <td>4.500151e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Els braços reial, militar i eclesiàstic lliura...</td>\n",
       "      <td>prohibició d'acudir a la justícia eclesiàstica</td>\n",
       "      <td>la prohibició d'acudir a la justícia eclesiàstica</td>\n",
       "      <td>3.655441e-08</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>8.091067e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El grup municipal de la CUP-Capgirem a l'Ajunt...</td>\n",
       "      <td>des del 2007</td>\n",
       "      <td>El grup municipal de la CUP-Capgirem a l'Ajunt...</td>\n",
       "      <td>4.730225e-04</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>2.658409e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El 1899 s'erigí una estàtua de Lesseps de més ...</td>\n",
       "      <td>bronze</td>\n",
       "      <td>bronze</td>\n",
       "      <td>2.956390e-04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.821832e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El 25 de juliol de 1713 l'exèrcit borbònic —un...</td>\n",
       "      <td>franco-espanyol</td>\n",
       "      <td>el franco-espanyol</td>\n",
       "      <td>8.866191e-07</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.531972e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>El 1972, el físic francès Francis Perrin desco...</td>\n",
       "      <td>235</td>\n",
       "      <td>urani 235</td>\n",
       "      <td>6.866455e-04</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.531972e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hi ha molts tipus de virus de les plantes, per...</td>\n",
       "      <td>en cèl·lules vegetals vives</td>\n",
       "      <td>en cèl·lules vegetals vives</td>\n",
       "      <td>1.792908e-04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Confirmades les quatre primeres morts per coro...</td>\n",
       "      <td>gitana</td>\n",
       "      <td>una era gitana, una altra era magribina, una a...</td>\n",
       "      <td>2.145767e-05</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>9.257325e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El bloc independentista superaria el 50% dels ...</td>\n",
       "      <td>Vox</td>\n",
       "      <td>Ciutadans</td>\n",
       "      <td>1.688004e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>El retaule consta d'una predel·la amb quatre r...</td>\n",
       "      <td>amb pa d'or</td>\n",
       "      <td>amb pa d'or</td>\n",
       "      <td>3.387451e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.221339e-77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Barcelona en Comú renunciarà a un regidor en t...   \n",
       "1  Els braços reial, militar i eclesiàstic lliura...   \n",
       "2  El grup municipal de la CUP-Capgirem a l'Ajunt...   \n",
       "3  El 1899 s'erigí una estàtua de Lesseps de més ...   \n",
       "4  El 25 de juliol de 1713 l'exèrcit borbònic —un...   \n",
       "5  El 1972, el físic francès Francis Perrin desco...   \n",
       "6  Hi ha molts tipus de virus de les plantes, per...   \n",
       "7  Confirmades les quatre primeres morts per coro...   \n",
       "8  El bloc independentista superaria el 50% dels ...   \n",
       "9  El retaule consta d'una predel·la amb quatre r...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  en totes les votacions del ple de l'Ajuntament...   \n",
       "1     prohibició d'acudir a la justícia eclesiàstica   \n",
       "2                                       des del 2007   \n",
       "3                                             bronze   \n",
       "4                                    franco-espanyol   \n",
       "5                                                235   \n",
       "6                        en cèl·lules vegetals vives   \n",
       "7                                             gitana   \n",
       "8                                                Vox   \n",
       "9                                        amb pa d'or   \n",
       "\n",
       "                                          prediction          prob        f1  \\\n",
       "0                                                 un  4.500151e-06  0.000000   \n",
       "1  la prohibició d'acudir a la justícia eclesiàstica  3.655441e-08  0.909091   \n",
       "2  El grup municipal de la CUP-Capgirem a l'Ajunt...  4.730225e-04  0.023077   \n",
       "3                                             bronze  2.956390e-04  1.000000   \n",
       "4                                 el franco-espanyol  8.866191e-07  0.666667   \n",
       "5                                          urani 235  6.866455e-04  0.666667   \n",
       "6                        en cèl·lules vegetals vives  1.792908e-04  1.000000   \n",
       "7  una era gitana, una altra era magribina, una a...  2.145767e-05  0.142857   \n",
       "8                                          Ciutadans  1.688004e-04  0.000000   \n",
       "9                                        amb pa d'or  3.387451e-03  1.000000   \n",
       "\n",
       "            bleu  \n",
       "0   0.000000e+00  \n",
       "1   8.091067e-01  \n",
       "2   2.658409e-79  \n",
       "3  1.821832e-231  \n",
       "4  1.531972e-231  \n",
       "5  1.531972e-231  \n",
       "6   1.000000e+00  \n",
       "7  9.257325e-232  \n",
       "8   0.000000e+00  \n",
       "9   1.221339e-77  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ca = catalanqa.map(compute_metrics)\n",
    "results_ca.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a429419-652f-4d6e-a2c1-a3161f2a13fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203cc21c3de345d7807ec86ac31d0500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/workspace/poligloteval/venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "      <th>f1</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barcelona en Comú will resign a councillor in ...</td>\n",
       "      <td>in all the votes of the plenary session of the...</td>\n",
       "      <td>when Joaquim Forn is not present in the plenary</td>\n",
       "      <td>1.349959e-20</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.441453e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The royal, military and ecclesiastical arms ha...</td>\n",
       "      <td>ban on going to ecclesiastical justice</td>\n",
       "      <td>The prohibition of going to ecclesiastical jus...</td>\n",
       "      <td>4.602043e-10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.111336e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The municipal group of the CUP-Capgirem in the...</td>\n",
       "      <td>since 2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.431870e-05</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.702145e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1899 a statue of Lesseps of more than 10 me...</td>\n",
       "      <td>bronze</td>\n",
       "      <td>bronze</td>\n",
       "      <td>3.314018e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.821832e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On July 25, 1713, the Bourbon army—about 25,00...</td>\n",
       "      <td>French-Spanish</td>\n",
       "      <td>the army of the Duke of Bourbon</td>\n",
       "      <td>1.722947e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In 1972, French physicist Francis Perrin disco...</td>\n",
       "      <td>235</td>\n",
       "      <td>235U</td>\n",
       "      <td>1.167297e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>There are many types of plant viruses, but the...</td>\n",
       "      <td>in living plant cells</td>\n",
       "      <td>in living plant cells</td>\n",
       "      <td>1.316071e-04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first four deaths from coronavirus in Nort...</td>\n",
       "      <td>gypsy</td>\n",
       "      <td>Roma community</td>\n",
       "      <td>3.464520e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The pro-independence bloc would exceed 50% of ...</td>\n",
       "      <td>Vox &amp; Vox</td>\n",
       "      <td>The independence blog</td>\n",
       "      <td>1.463718e-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The altarpiece consists of a predella with fou...</td>\n",
       "      <td>with gold leaf</td>\n",
       "      <td>with gilded pacarriers</td>\n",
       "      <td>2.840534e-08</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.384293e-231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Barcelona en Comú will resign a councillor in ...   \n",
       "1  The royal, military and ecclesiastical arms ha...   \n",
       "2  The municipal group of the CUP-Capgirem in the...   \n",
       "3  In 1899 a statue of Lesseps of more than 10 me...   \n",
       "4  On July 25, 1713, the Bourbon army—about 25,00...   \n",
       "5  In 1972, French physicist Francis Perrin disco...   \n",
       "6  There are many types of plant viruses, but the...   \n",
       "7  The first four deaths from coronavirus in Nort...   \n",
       "8  The pro-independence bloc would exceed 50% of ...   \n",
       "9  The altarpiece consists of a predella with fou...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  in all the votes of the plenary session of the...   \n",
       "1             ban on going to ecclesiastical justice   \n",
       "2                                         since 2007   \n",
       "3                                             bronze   \n",
       "4                                     French-Spanish   \n",
       "5                                                235   \n",
       "6                              in living plant cells   \n",
       "7                                              gypsy   \n",
       "8                                          Vox & Vox   \n",
       "9                                     with gold leaf   \n",
       "\n",
       "                                          prediction          prob        f1  \\\n",
       "0    when Joaquim Forn is not present in the plenary  1.349959e-20  0.333333   \n",
       "1  The prohibition of going to ecclesiastical jus...  4.602043e-10  0.666667   \n",
       "2                                               2007  2.431870e-05  0.666667   \n",
       "3                                             bronze  3.314018e-05  1.000000   \n",
       "4                    the army of the Duke of Bourbon  1.722947e-08  0.000000   \n",
       "5                                               235U  1.167297e-03  0.000000   \n",
       "6                              in living plant cells  1.316071e-04  1.000000   \n",
       "7                                     Roma community  3.464520e-07  0.000000   \n",
       "8                              The independence blog  1.463718e-12  0.000000   \n",
       "9                             with gilded pacarriers  2.840534e-08  0.333333   \n",
       "\n",
       "            bleu  \n",
       "0  1.441453e-155  \n",
       "1   4.111336e-01  \n",
       "2  6.702145e-232  \n",
       "3  1.821832e-231  \n",
       "4   0.000000e+00  \n",
       "5   0.000000e+00  \n",
       "6   1.000000e+00  \n",
       "7   0.000000e+00  \n",
       "8   0.000000e+00  \n",
       "9  1.384293e-231  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_en = catalanqa_en.map(compute_metrics)\n",
    "results_en.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ca.to_csv(f\"results/{model_name}-viquiquad-ca.csv\", index=False)\n",
    "results_en.to_csv(f\"results/{model_name}-viquiquad-en.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== CA =====\n",
      "prob    0.700586\n",
      "f1      0.540836\n",
      "bleu    0.180911\n",
      "dtype: float64\n",
      "==== EN =====\n",
      "prob    0.532715\n",
      "f1      0.400000\n",
      "bleu    0.141113\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_ca_mean = results_ca.to_pandas()[['prob', 'f1', 'bleu']].mean()\n",
    "results_en_mean = results_en.to_pandas()[['prob', 'f1', 'bleu']].mean()\n",
    "print(\"==== CA =====\")\n",
    "print(results_ca_mean)\n",
    "print(\"==== EN =====\")\n",
    "print(results_en_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== CA =====\n",
      "prob    0.000522\n",
      "f1      0.540836\n",
      "bleu    0.180911\n",
      "dtype: float64\n",
      "==== EN =====\n",
      "prob    0.000136\n",
      "f1      0.400000\n",
      "bleu    0.141113\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_ca_mean = results_ca.to_pandas()[['prob', 'f1', 'bleu']].mean()\n",
    "results_en_mean = results_en.to_pandas()[['prob', 'f1', 'bleu']].mean()\n",
    "print(\"==== CA =====\")\n",
    "print(results_ca_mean)\n",
    "print(\"==== EN =====\")\n",
    "print(results_en_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
